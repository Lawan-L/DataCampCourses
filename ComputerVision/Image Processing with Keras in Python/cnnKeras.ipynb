{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnKeras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOqZJnKs3-n9"
      },
      "source": [
        "it ressembles  a dense layer, but instead of having every unit connected to every unit in the previous layer, theses connect to the previous layer through a convolution kernel. that means the output of each unit in this layer is a convolution of a kernel over the image input \n",
        "\n",
        "during the training, the kernels in each unit would be adjusted using back_propagation, the principle is the same as learning in the dense layers, that we have seen so far, but with fewer weights\n",
        "\n",
        "A dense layer has one weight for each pixel in the image, but a CNN has only one weight for each pixel in the kernel.\n",
        "\n",
        "For example, k_size = 3 means the kernel of each unit has 9 pixels.\n",
        "so, if the layer has 10 units, it would have 90 parameters for theses kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRVG66AL3u9_",
        "outputId": "cc3f9307-c0cc-4309-aa44-1fa13c80e532"
      },
      "source": [
        "from keras.layers import Conv2D\n",
        "Conv2D(10, kernel_size=3, activation=\"relu \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f4cdddeaa50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xYVGRFDSEhv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCg5GB8oSH2s"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keas.layers import Dense, Conv2D, Flatten\n",
        "n_channel = 1\n",
        "model = Sequential()\n",
        "model.add(Conv2D(10, kernel_size=3, activation=\"relu\", input_shape=(imgRows, imgCols, n_channel)))\n",
        "# flatten layer serves connction between convolution and densly connected layers\n",
        "#taking the output of convolution which is referred as a feature map\n",
        "# and flattens it into a 1D array\n",
        "#this is the expecte input for the densely connected layer\n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVW4wmkRc1c0"
      },
      "source": [
        "#ex1\n",
        "Convolutional network for image classification\n",
        "\n",
        "Convolutional networks for classification are constructed from a sequence of convolutional layers (for image processing) and fully connected (Dense) layers (for readout). In this exercise, you will construct a small convolutional network for classification of the data from the fashion dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bavvb_Cc2f7"
      },
      "source": [
        "# Import the necessary components from Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "# Initialize the model object\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "               input_shape=(img_cols, img_cols,1)))\n",
        "\n",
        "# Flatten the output of the convolutional layer\n",
        "model.add(Flatten())\n",
        "# Add an output layer for the 3 categories\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7EV2gijdqXP"
      },
      "source": [
        "Training a CNN to classify clothing types\n",
        "\n",
        "Before training a neural network it needs to be compiled with the right cost function, using the right optimizer. During compilation, you can also define metrics that the network calculates and reports in every epoch. Model fitting requires a training data set, together with the training labels to the network.\n",
        "\n",
        "The Conv2D model you built in the previous exercise is available in your workspace\n",
        "\n",
        "- Evaluate the data on a separate test set: test_data and test_labels.\n",
        "- Use the same batch size that was used for fitting (10 images per batch).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOzjZU0dq79"
      },
      "source": [
        "# Compile the model \n",
        "model.compile(optimizer=\"adam\", \n",
        "              loss=\"categorical_crossentropy\", \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model on a training set\n",
        "model.fit(train_data, train_labels, \n",
        "          validation_split=.2, \n",
        "          epochs=3, batch_size=10)\n",
        "\n",
        "# Evaluate the model on separate test data\n",
        "model.evaluate(test_data, test_labels, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yayb-GwfdbSf"
      },
      "source": [
        ""
      ]
    }
  ]
}